#!/usr/bin/env python3  
# -*- coding: utf-8 -*-
"""
åŸºäºLangGraphçš„è®ºå›åˆ†æå™¨
ä½¿ç”¨ä¼˜åŒ–çš„é¢„å¤„ç†å’Œæ‰¹é‡åˆ†ææµç¨‹
"""

import json
import sys
from typing import Dict, Any
from graph.workflow import compile_multimodal_workflow
from graph.state import ContentType


def load_forum_data(file_path: str) -> Dict[str, Any]:
    """åŠ è½½è®ºå›æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def analyze_forum_with_langgraph(forum_json_data: Dict[str, Any]) -> Dict[str, Any]:
    """ä½¿ç”¨LangGraphåˆ†æè®ºå›æ•°æ®"""
    
    # ç¼–è¯‘å·¥ä½œæµ
    workflow = compile_multimodal_workflow()
    
    # å‡†å¤‡åˆå§‹çŠ¶æ€
    initial_state = {
        "analysis_requests": [],  # è®ºå›åˆ†æä¸»è¦é€šè¿‡forum_dataå¤„ç†
        "forum_data": forum_json_data,  # ç›´æ¥ä¼ å…¥è®ºå›æ•°æ®
        "analysis_results": [],
        "final_summary": None,
        "consolidated_key_points": [],
        "current_step": "ready",
        "messages": [],
        "metadata": {
            "workflow_type": "forum_analysis",
            "source": "langgraph_forum_analyzer"
        }
    }
    
    print("ğŸš€ å¯åŠ¨LangGraphè®ºå›åˆ†æå·¥ä½œæµ...")
    print("="*60)
    
    try:
        # æ‰§è¡Œå·¥ä½œæµ
        result = workflow.invoke(initial_state)
        
        print("\n" + "="*60)
        print("ğŸ‰ LangGraphå·¥ä½œæµæ‰§è¡Œå®Œæˆ!")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
        return {"error": str(e), "success": False}


def print_workflow_results(result: Dict[str, Any]):
    """æ‰“å°å·¥ä½œæµç»“æœ"""
    if result.get("error"):
        print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
        return
    
    print("\nğŸ“‹ å·¥ä½œæµæ‰§è¡Œæ‘˜è¦:")
    print(f"  - å½“å‰æ­¥éª¤: {result.get('current_step', 'unknown')}")
    print(f"  - å¤„ç†æ¶ˆæ¯: {len(result.get('messages', []))}")
    print(f"  - åˆ†æç»“æœ: {len(result.get('analysis_results', []))}")
    
    # æ˜¾ç¤ºè®ºå›åˆ†æç‰¹å®šä¿¡æ¯
    analysis_results = result.get("analysis_results", [])
    forum_results = [r for r in analysis_results if r.get("content_type") == ContentType.FORUM]
    
    if forum_results:
        forum_result = forum_results[0]
        metadata = forum_result.get("metadata", {})
        print(f"\nğŸ“Š è®ºå›åˆ†æç»Ÿè®¡:")
        print(f"  - æ€»å¸–å­æ•°: {metadata.get('total_posts', 0)}")
        print(f"  - å‚ä¸ç”¨æˆ·: {metadata.get('users_count', 0)}äºº")
        print(f"  - å¤–éƒ¨é“¾æ¥: {metadata.get('links_count', 0)}ä¸ª")
        print(f"  - å›¾ç‰‡å†…å®¹: {metadata.get('images_count', 0)}å¼ ")
        print(f"  - åˆ†æç½®ä¿¡åº¦: {forum_result.get('confidence', 0):.2f}")
        
        # æ˜¾ç¤ºåª’ä½“åˆ†æç»“æœ
        media_results = [r for r in analysis_results if r.get("content_type") in [ContentType.URL, ContentType.IMAGE]]
        if media_results:
            print(f"  - åª’ä½“å†…å®¹åˆ†æ: {len(media_results)}é¡¹")
    
    # å¦‚æœæœ‰æœ€ç»ˆæŠ¥å‘Šï¼Œæ˜¾ç¤ºå®ƒ
    if result.get("final_report"):
        print("\n" + result["final_report"])


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python langgraph_forum_analyzer.py <jsonæ–‡ä»¶è·¯å¾„>")
        print("ç¤ºä¾‹: python langgraph_forum_analyzer.py sample_forum_data.json")
        return
    
    file_path = sys.argv[1]
    
    try:
        # åŠ è½½è®ºå›æ•°æ®
        print(f"ğŸ“‚ åŠ è½½è®ºå›æ•°æ®: {file_path}")
        forum_data = load_forum_data(file_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {forum_data.get('topicTitle', '')}")
        
        # ä½¿ç”¨LangGraphåˆ†æ
        result = analyze_forum_with_langgraph(forum_data)
        
        # æ˜¾ç¤ºç»“æœ
        print_workflow_results(result)
        
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {str(e)}")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")


if __name__ == "__main__":
    main()