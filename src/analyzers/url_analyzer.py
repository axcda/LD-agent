from typing import Dict, Any
import requests
from bs4 import BeautifulSoup
from src.analyzers.base import ContentAnalyzer
from src.graph.state import AnalysisResult, ContentType


class URLAnalyzer(ContentAnalyzer):
    """URLå†…å®¹åˆ†æžå™¨"""
    
    def __init__(self):
        super().__init__()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
    
    def fetch_url_content(self, url: str) -> str:
        """èŽ·å–URLå†…å®¹"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # è§£æžHTMLå†…å®¹
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼
            for script in soup(["script", "style"]):
                script.decompose()
            
            # æå–ä¸»è¦æ–‡æœ¬å†…å®¹
            title = soup.find('title')
            title_text = title.get_text() if title else "æ— æ ‡é¢˜"
            
            # æå–æ­£æ–‡å†…å®¹
            content_tags = soup.find_all(['p', 'h1', 'h2', 'h3', 'article', 'main'])
            content_text = '\n'.join([tag.get_text().strip() for tag in content_tags if tag.get_text().strip()])
            
            return f"æ ‡é¢˜: {title_text}\n\nå†…å®¹: {content_text[:2000]}..."
            
        except Exception as e:
            return f"æ— æ³•èŽ·å–URLå†…å®¹: {str(e)}"
    
    def analyze_url(self, url: str) -> AnalysisResult:
        """åˆ†æžURLå†…å®¹"""
        print(f"ðŸ“¥ å¼€å§‹åˆ†æžURL: {url}")
        
        # èŽ·å–ç½‘é¡µå†…å®¹
        web_content = self.fetch_url_content(url)
        
        # åˆ›å»ºåˆ†æžæç¤º
        prompt = f"""
        è¯·åˆ†æžä»¥ä¸‹ç½‘é¡µå†…å®¹ï¼š
        
        URL: {url}
        å†…å®¹: {web_content}
        
        è¯·æä¾›ï¼š
        1. ç½‘é¡µä¸»é¢˜å’Œæ ¸å¿ƒå†…å®¹æ€»ç»“
        2. å…³é”®ä¿¡æ¯å’Œè¦ç‚¹
        3. å†…å®¹çš„å¯ä¿¡åº¦å’Œä»·å€¼è¯„ä¼°
        4. å¯¹è¯»è€…çš„å®žç”¨æ€§å»ºè®®
        
        è¯·ç”¨ç®€æ´æ˜Žäº†çš„è¯­è¨€æ€»ç»“ï¼Œçªå‡ºæœ€é‡è¦çš„ä¿¡æ¯ã€‚
        """
        
        # ä½¿ç”¨AIåˆ†æž
        analysis = self.analyze_with_openai(prompt)
        
        if "å¤±è´¥" in analysis:
            analysis = self.analyze_with_gemini(prompt)
        
        # æå–å…³é”®ç‚¹
        key_points = self._extract_key_points(analysis)
        
        # è¯„ä¼°ç½®ä¿¡åº¦
        confidence = 0.8 if "å¤±è´¥" not in analysis else 0.3
        if "æ— æ³•èŽ·å–" in web_content:
            confidence = 0.1
        
        return {
            "content_type": ContentType.URL,
            "original_content": url,
            "analysis": analysis,
            "summary": analysis[:300] + "..." if len(analysis) > 300 else analysis,
            "key_points": key_points,
            "confidence": confidence
        }