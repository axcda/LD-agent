from typing import Dict, Any
import requests
import base64
from PIL import Image
import io
from src.analyzers.base import ContentAnalyzer
from src.graph.state import AnalysisResult, ContentType


class ImageAnalyzer(ContentAnalyzer):
    """å›¾ç‰‡å†…å®¹åˆ†æžå™¨"""
    
    def __init__(self):
        super().__init__()
    
    def download_image(self, image_url: str) -> str:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64"""
        try:
            response = requests.get(image_url, timeout=10)
            response.raise_for_status()
            
            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            return f"data:image/jpeg;base64,{image_base64}"
            
        except Exception as e:
            return f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {str(e)}"
    
    def analyze_image(self, image_url: str) -> AnalysisResult:
        """åˆ†æžå›¾ç‰‡å†…å®¹"""
        print(f"ðŸ–¼ï¸ å¼€å§‹åˆ†æžå›¾ç‰‡: {image_url}")
        
        # é¦–å…ˆå°è¯•ä¸‹è½½å›¾ç‰‡
        image_data = self.download_image(image_url)
        
        # åˆ›å»ºåˆ†æžæç¤º
        prompt = f"""
        è¯·åˆ†æžè¿™å¼ å›¾ç‰‡ï¼š
        
        å›¾ç‰‡URL: {image_url}
        
        è¯·æä¾›ï¼š
        1. å›¾ç‰‡ä¸»è¦å†…å®¹å’Œåœºæ™¯æè¿°
        2. å›¾ç‰‡ä¸­çš„å…³é”®å…ƒç´ å’Œç»†èŠ‚
        3. å›¾ç‰‡çš„ç”¨é€”å’ŒèƒŒæ™¯åˆ†æž
        4. å›¾ç‰‡è´¨é‡å’ŒæŠ€æœ¯ç‰¹ç‚¹
        
        è¯·è¯¦ç»†æè¿°ä½ åœ¨å›¾ç‰‡ä¸­çœ‹åˆ°çš„å†…å®¹ã€‚
        """
        
        # å°è¯•ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼åˆ†æžå›¾ç‰‡ï¼ˆä¼ é€’å®žé™…å›¾ç‰‡æ•°æ®ï¼‰
        if not image_data.startswith("å›¾ç‰‡ä¸‹è½½å¤±è´¥"):
            # å¦‚æžœå›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œä¼ é€’base64æ•°æ®ç»™é˜¿é‡Œç™¾ç‚¼
            analysis = self.analyze_with_alibaba(prompt, image_data)
        else:
            # å¦‚æžœä¸‹è½½å¤±è´¥ï¼Œä»ç„¶ä½¿ç”¨URLè¿›è¡Œåˆ†æž
            analysis = self.analyze_with_alibaba(prompt, image_url)
        
        # å¦‚æžœé˜¿é‡Œç™¾ç‚¼å¤±è´¥ï¼Œæä¾›æ›´å¥½çš„é”™è¯¯å¤„ç†
        if "å¤±è´¥" in analysis:
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if image_data.startswith("å›¾ç‰‡ä¸‹è½½å¤±è´¥"):
                analysis = f"å›¾ç‰‡åˆ†æž: {image_url}\næ— æ³•ä¸‹è½½æˆ–è®¿é—®æ­¤å›¾ç‰‡ï¼Œå¯èƒ½æ˜¯å› ä¸ºç½‘ç»œé—®é¢˜æˆ–å›¾ç‰‡ä¸å­˜åœ¨ã€‚"
            else:
                analysis = f"å›¾ç‰‡åˆ†æž: {image_url}\nè™½ç„¶å›¾ç‰‡å·²ä¸‹è½½ï¼Œä½†æ— æ³•è¿›è¡Œè¯¦ç»†åˆ†æžã€‚è¿™å¯èƒ½æ˜¯ä¸€å¼ ç›¸å…³çš„å›¾ç‰‡ï¼Œä½†éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡æ¥ç†è§£å…¶å†…å®¹ã€‚"
        
        # æå–å…³é”®ç‚¹
        key_points = self.extractKeyPoints(analysis)
        
        # è¯„ä¼°ç½®ä¿¡åº¦
        confidence = 0.7 if "å¤±è´¥" not in analysis else 0.3
        
        return {
            "content_type": ContentType.IMAGE,
            "original_content": image_url,
            "analysis": analysis,
            "summary": analysis[:300] + "..." if len(analysis) > 300 else analysis,
            "key_points": key_points,
            "confidence": confidence
        }