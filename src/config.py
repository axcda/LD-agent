import os
from dotenv import load_dotenv
from typing import Optional
import openai
import google.generativeai as genai
import dashscope
import requests
import json
import logging

load_dotenv()
logger = logging.getLogger(__name__)

# å®šä¹‰å¸¸è§çš„OpenAI APIé™åˆ¶é”™è¯¯æ¶ˆæ¯
OPENAI_RATE_LIMIT_ERRORS = [
    "rate_limit_exceeded",
    "insufficient_quota",
    "quota_exceeded",
    "Rate limit reached",
    "You exceeded your current quota",
    "Request rate limit exceeded"
]

class CustomOpenAIClient:
    """è‡ªå®šä¹‰OpenAIå®¢æˆ·ç«¯ï¼Œç”¨äºå¤„ç†éæ ‡å‡†ç«¯ç‚¹"""
    
    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.chat = self.ChatCompletions(self)
    
    class ChatCompletions:
        def __init__(self, client):
            self.client = client
            self.completions = self.Completions(client)
        
        class Completions:
            def __init__(self, client):
                self.client = client
            
            def create(self, model: str, messages: list, max_tokens: int = None, temperature: float = None, **kwargs):
                """åˆ›å»ºèŠå¤©å®Œæˆè¯·æ±‚ - æ™ºèƒ½é€‚é…ä¸åŒAPIæ ¼å¼"""
                headers = {
                    'Authorization': f'Bearer {self.client.api_key}',
                    'Content-Type': 'application/json'
                }
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šçš„ Responses API ç«¯ç‚¹
                is_responses_api = '/v1/responses' in self.client.base_url
                
                if is_responses_api:
                    # --- è¿™éƒ¨åˆ†é€»è¾‘ä¿æŒä¸å˜ï¼Œç”¨äºå¤„ç†ç‰¹æ®Šçš„ /v1/responses API ---
                    user_input = ""
                    for message in messages:
                        if message.get('role') == 'user':
                            user_input = message.get('content', '')
                    
                    data = {
                        'model': model,
                        'input': user_input
                    }
                    
                    if temperature is not None:
                        data['temperature'] = temperature
                    
                    supported_params = ['temperature', 'top_p', 'frequency_penalty', 'presence_penalty']
                    for key, value in kwargs.items():
                        if key in supported_params and value is not None:
                            data[key] = value
                    
                    endpoint_url = self.client.base_url
                else:
                    # --- è¿™éƒ¨åˆ†æ˜¯ä¸ºæ ‡å‡† OpenAI API ä¿®æ­£çš„é€»è¾‘ ---
                    data = {
                        'model': model,
                        'messages': messages
                    }
                    
                    if max_tokens is not None:
                        data['max_tokens'] = max_tokens
                    if temperature is not None:
                        data['temperature'] = temperature
                    
                    data.update(kwargs)
                    
                    # ä¿®æ­£åçš„URLæ„å»ºé€»è¾‘
                    base_url = self.client.base_url.rstrip('/')
                    
                    if base_url.endswith('/chat/completions'):
                        # å¦‚æœbase_urlå·²ç»åŒ…å«äº†å®Œæ•´çš„ç«¯ç‚¹
                        endpoint_url = base_url
                    else:
                        # å¦åˆ™ï¼Œæˆ‘ä»¬å‡è®¾å®ƒæ˜¯ä¸€ä¸ªåŸºç¡€URLï¼Œéœ€è¦é™„åŠ æ ‡å‡†ç«¯ç‚¹
                        # ç¤ºä¾‹: "https://api.openai.com/v1" -> "https://api.openai.com/v1/chat/completions"
                        endpoint_url = f"{base_url}/chat/completions"
                
                try:
                    logger.debug(f"ğŸ”— è¯·æ±‚ç«¯ç‚¹: {endpoint_url}")
                    # ä½¿ç”¨ ensure_ascii=False å¯ä»¥åœ¨æ—¥å¿—ä¸­æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
                    logger.debug(f"ğŸ“‹ è¯·æ±‚æ•°æ®: {json.dumps(data, indent=2, ensure_ascii=False)}")
                    
                    response = requests.post(
                        endpoint_url,
                        headers=headers,
                        json=data,
                        timeout=60 # å»ºè®®å°†è¶…æ—¶æ—¶é—´è®¾ç½®å¾—é•¿ä¸€äº›
                    )
                    
                    response.raise_for_status()
                    response_data = response.json()
                    
                    return CustomResponse(response_data)
                    
                except requests.exceptions.RequestException as e:
                    error_message = f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
                    if e.response is not None:
                        try:
                            # å°è¯•ä»¥JSONæ ¼å¼è§£æé”™è¯¯è¯¦æƒ…ï¼Œå¹¶æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
                            error_details = e.response.json()
                            error_message += f"\nå“åº”å†…å®¹: {json.dumps(error_details, indent=2, ensure_ascii=False)}"
                        except json.JSONDecodeError:
                            error_message += f"\nå“åº”å†…å®¹ (éJSON): {e.response.text}"
                    raise Exception(error_message)


class CustomResponse:
    """è‡ªå®šä¹‰å“åº”å¯¹è±¡ï¼Œå…¼å®¹OpenAIå“åº”æ ¼å¼"""
    
    def __init__(self, data: dict):
        self.choices = []
        
        # å¤„ç†Responses APIæ ¼å¼
        if 'output' in data:
            # Responses APIæ ¼å¼
            for output_item in data.get('output', []):
                if output_item.get('type') == 'message':
                    content_parts = output_item.get('content', [])
                    content_text = ""
                    for part in content_parts:
                        if part.get('type') == 'output_text':
                            content_text += part.get('text', '')
                    
                    choice_data = {
                        'message': {
                            'content': content_text,
                            'role': output_item.get('role', 'assistant')
                        }
                    }
                    self.choices.append(CustomChoice(choice_data))
        elif 'choices' in data:
            # æ ‡å‡†Chat Completionsæ ¼å¼
            self.choices = [CustomChoice(choice) for choice in data.get('choices', [])]
        else:
            self.choices = []


class CustomChoice:
    """è‡ªå®šä¹‰é€‰æ‹©å¯¹è±¡"""
    
    def __init__(self, data: dict):
        self.message = CustomMessage(data.get('message', {}))


class CustomMessage:
    """è‡ªå®šä¹‰æ¶ˆæ¯å¯¹è±¡"""
    
    def __init__(self, data: dict):
        self.content = data.get('content', '')
        self.role = data.get('role', 'assistant')


class MultiKeyOpenAIClient:
    """æ”¯æŒå¤šå¯†é’¥è‡ªåŠ¨åˆ‡æ¢çš„OpenAIå®¢æˆ·ç«¯"""
    
    def __init__(self, api_keys: list, base_url: str):
        if not api_keys:
            raise ValueError("è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªAPIå¯†é’¥")
        
        self.api_keys = api_keys
        self.base_url = base_url.rstrip('/')
        self.current_key_index = 0
        self.chat = self.ChatCompletions(self)
    
    @property
    def current_api_key(self):
        """è·å–å½“å‰ä½¿ç”¨çš„APIå¯†é’¥"""
        return self.api_keys[self.current_key_index]
    
    def switch_to_next_key(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIå¯†é’¥"""
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        logger.info(f"ğŸ”„ åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIå¯†é’¥ï¼Œå½“å‰ä½¿ç”¨ç¬¬ {self.current_key_index + 1}/{len(self.api_keys)} ä¸ªå¯†é’¥")
    
    def is_rate_limit_error(self, error_message: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé€Ÿç‡é™åˆ¶é”™è¯¯"""
        error_lower = error_message.lower()
        for rate_limit_error in OPENAI_RATE_LIMIT_ERRORS:
            if rate_limit_error.lower() in error_lower:
                return True
        return False
    
    class ChatCompletions:
        def __init__(self, client):
            self.client = client
            self.completions = self.Completions(client)
        
        class Completions:
            def __init__(self, client):
                self.client = client
            
            def create(self, model: str, messages: list, max_tokens: int = None, temperature: float = None, **kwargs):
                """åˆ›å»ºèŠå¤©å®Œæˆè¯·æ±‚ - æ”¯æŒå¤šå¯†é’¥è‡ªåŠ¨åˆ‡æ¢"""
                # ä¿å­˜åŸå§‹å‚æ•°ï¼Œç”¨äºé‡è¯•æ—¶ä½¿ç”¨
                original_params = {
                    'model': model,
                    'messages': messages,
                    'max_tokens': max_tokens,
                    'temperature': temperature,
                    **kwargs
                }
                
                # å°è¯•æ¬¡æ•°è®¡æ•°å™¨
                attempt_count = 0
                max_attempts = len(self.client.api_keys)
                
                while attempt_count < max_attempts:
                    # ä½¿ç”¨å½“å‰å¯†é’¥åˆ›å»ºå®¢æˆ·ç«¯
                    current_client = CustomOpenAIClient(
                        api_key=self.client.current_api_key,
                        base_url=self.client.base_url
                    )
                    
                    try:
                        # å°è¯•æ‰§è¡Œè¯·æ±‚
                        return current_client.chat.completions.create(**original_params)
                    except Exception as e:
                        error_message = str(e)
                        logger.warning(f"âš ï¸ APIè¯·æ±‚å¤±è´¥ (å¯†é’¥ {self.client.current_key_index + 1}/{len(self.client.api_keys)}): {error_message}")
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºé€Ÿç‡é™åˆ¶é”™è¯¯
                        if self.client.is_rate_limit_error(error_message):
                            # å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯†é’¥
                            self.client.switch_to_next_key()
                            attempt_count += 1
                            
                            # å¦‚æœå·²ç»å°è¯•è¿‡æ‰€æœ‰å¯†é’¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                            if attempt_count >= max_attempts:
                                logger.error("âŒ æ‰€æœ‰APIå¯†é’¥éƒ½å·²è¾¾åˆ°é™åˆ¶")
                                raise Exception(f"æ‰€æœ‰APIå¯†é’¥éƒ½å·²è¾¾åˆ°é™åˆ¶: {error_message}")
                        else:
                            # å¦‚æœä¸æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
                            raise e
                
                # å¦‚æœå¾ªç¯ç»“æŸä»æœªæˆåŠŸï¼ŒæŠ›å‡ºå¼‚å¸¸
                raise Exception("APIè¯·æ±‚å¤±è´¥ï¼Œå·²å°è¯•æ‰€æœ‰å¯†é’¥")


class Config:
    """é…ç½®ç®¡ç†ç±»"""
    
    def __init__(self):
        # è¯»å–å•ä¸ªAPIå¯†é’¥ï¼ˆå‘åå…¼å®¹ï¼‰
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if self.openai_api_key:
            openai.api_key = self.openai_api_key
            
        # è¯»å–å¤šä¸ªAPIå¯†é’¥
        openai_api_keys_str = os.getenv("OPENAI_API_KEYS")
        if openai_api_keys_str:
            # åˆ†å‰²å¹¶æ¸…ç†å¯†é’¥
            self.openai_api_keys = [key.strip() for key in openai_api_keys_str.split(",") if key.strip()]
        else:
            # å¦‚æœæ²¡æœ‰é…ç½®å¤šä¸ªå¯†é’¥ï¼Œä½†é…ç½®äº†å•ä¸ªå¯†é’¥ï¼Œåˆ™ä½¿ç”¨å•ä¸ªå¯†é’¥
            self.openai_api_keys = [self.openai_api_key] if self.openai_api_key else []
            
        self.openai_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        
        self.google_api_key = os.getenv("GOOGLE_API_KEY")
        if self.google_api_key:
            genai.configure(api_key=self.google_api_key)
        
        self.alibaba_api_key = os.getenv("ALIBABA_API_KEY")
        if self.alibaba_api_key:
            dashscope.api_key = self.alibaba_api_key
        
        self.max_tokens = int(os.getenv("MAX_TOKENS", 32768))
        self.temperature = float(os.getenv("TEMPERATURE", 0.7))
        
        # Smithery MCPé…ç½®
        self.smithery_mcp_key = os.getenv("SMITHEREY_MCP_KEY")
        self.smithery_mcp_profile = os.getenv("SMITHEREY_MCP_PROFILE")
        
        # Tavilyé…ç½®
        self.tavily_api_key = os.getenv("TAVILY_API_KEY")
    
    def get_openai_client(self):
        """è·å–OpenAIå®¢æˆ·ç«¯"""
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†APIå¯†é’¥
        if not self.openai_api_keys:
            raise ValueError("OpenAI APIå¯†é’¥æœªé…ç½®")
        
        base_url = self.openai_base_url.rstrip('/')
        # å¦‚æœé…ç½®äº†å¤šä¸ªAPIå¯†é’¥ï¼Œè¿”å›å¤šå¯†é’¥å®¢æˆ·ç«¯
        if len(self.openai_api_keys) > 1:
            return MultiKeyOpenAIClient(api_keys=self.openai_api_keys, base_url=base_url)
        else:
            # å¦‚æœåªæœ‰ä¸€ä¸ªAPIå¯†é’¥ï¼Œè¿”å›åŸæ¥çš„å®¢æˆ·ç«¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            return CustomOpenAIClient(api_key=self.openai_api_keys[0], base_url=base_url)
    
    def get_gemini_model(self, model_name: str = "gemini-2.5-flash"):
        """è·å–Geminiæ¨¡å‹"""
        if not self.google_api_key:
            raise ValueError("Google APIå¯†é’¥æœªé…ç½®")
        return genai.GenerativeModel(model_name)
    
    def get_smithery_mcp_config(self):
        """è·å–Smithery MCPé…ç½®"""
        if not self.smithery_mcp_key or not self.smithery_mcp_profile:
            return None
        
        return {
            "key": self.smithery_mcp_key,
            "profile": self.smithery_mcp_profile
        }
    
    def validate_config(self) -> dict:
        """éªŒè¯é…ç½®"""
        status = {
            "openai": bool(self.openai_api_keys),
            "gemini": bool(self.google_api_key),
            "alibaba": bool(self.alibaba_api_key),
            "smithery_mcp": bool(self.smithery_mcp_key and self.smithery_mcp_profile)
        }
        return status


# å…¨å±€é…ç½®å®ä¾‹
config = Config()